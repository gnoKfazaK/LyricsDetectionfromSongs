{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>vocal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   file_name  lyrics  vocal\n",
       "0          1       1      1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'file_name':[1], 'lyrics':[1] , 'vocal':[1] })\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[0, 'lyrics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\CUHK\\IERG4320\\Project\\SongToLyrics\n"
     ]
    }
   ],
   "source": [
    "%cd SongToLyrics/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the vocal by hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first 5 songs are from Chris Martin - Coldplay\n",
    "for x in range(1, 6):\n",
    "    with open(f'./dataset/song_{x}.txt', 'r') as f:\n",
    "        df.loc[x - 1, 'lyrics'] = f.read()\n",
    "        df.loc[x - 1, 'file_name'] = f'song_{x}.mp3'\n",
    "        df.loc[x - 1, 'vocal'] = 'Chris Martin - Coldplay'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>vocal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>song_1.mp3</td>\n",
       "      <td>Look at the stars, look how they shine for you...</td>\n",
       "      <td>Chris Martin - Coldplay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>song_2.mp3</td>\n",
       "      <td>'Cause you're a sky, 'cause you're a sky full ...</td>\n",
       "      <td>Chris Martin - Coldplay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>song_3.mp3</td>\n",
       "      <td>I used to rule the world\\nSeas would rise when...</td>\n",
       "      <td>Chris Martin - Coldplay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>song_4.mp3</td>\n",
       "      <td>Ooh-ooh-ooh, ooh-ooh-ooh, ooh-ooh-ooh\\nOoh-ooh...</td>\n",
       "      <td>Chris Martin - Coldplay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>song_5.mp3</td>\n",
       "      <td>When you try your best, but you don't succeed\\...</td>\n",
       "      <td>Chris Martin - Coldplay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>song_6.mp3</td>\n",
       "      <td>Uh-huh, life's like this\\nUh-huh, uh-huh\\nThat...</td>\n",
       "      <td>Avril Lavigne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>song_7.mp3</td>\n",
       "      <td>I always needed time on my own\\nI never though...</td>\n",
       "      <td>Avril Lavigne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>song_8.mp3</td>\n",
       "      <td>I can be tough, I can be strong\\nBut with you,...</td>\n",
       "      <td>Avril Lavigne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>song_9.mp3</td>\n",
       "      <td>Hey, hey, you, you, I don't like your girlfrie...</td>\n",
       "      <td>Avril Lavigne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>song_10.mp3</td>\n",
       "      <td>You say that I'm messing with your head\\n(Yeah...</td>\n",
       "      <td>Avril Lavigne</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     file_name                                             lyrics  \\\n",
       "0   song_1.mp3  Look at the stars, look how they shine for you...   \n",
       "1   song_2.mp3  'Cause you're a sky, 'cause you're a sky full ...   \n",
       "2   song_3.mp3  I used to rule the world\\nSeas would rise when...   \n",
       "3   song_4.mp3  Ooh-ooh-ooh, ooh-ooh-ooh, ooh-ooh-ooh\\nOoh-ooh...   \n",
       "4   song_5.mp3  When you try your best, but you don't succeed\\...   \n",
       "5   song_6.mp3  Uh-huh, life's like this\\nUh-huh, uh-huh\\nThat...   \n",
       "6   song_7.mp3  I always needed time on my own\\nI never though...   \n",
       "7   song_8.mp3  I can be tough, I can be strong\\nBut with you,...   \n",
       "8   song_9.mp3  Hey, hey, you, you, I don't like your girlfrie...   \n",
       "9  song_10.mp3  You say that I'm messing with your head\\n(Yeah...   \n",
       "\n",
       "                     vocal  \n",
       "0  Chris Martin - Coldplay  \n",
       "1  Chris Martin - Coldplay  \n",
       "2  Chris Martin - Coldplay  \n",
       "3  Chris Martin - Coldplay  \n",
       "4  Chris Martin - Coldplay  \n",
       "5            Avril Lavigne  \n",
       "6            Avril Lavigne  \n",
       "7            Avril Lavigne  \n",
       "8            Avril Lavigne  \n",
       "9            Avril Lavigne  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first 5 songs are from Avril Lavigne\n",
    "for x in range(6, 11):\n",
    "    with open(f'./dataset/song_{x}.txt', 'r') as f:\n",
    "        df.loc[x - 1, 'lyrics'] = f.read()\n",
    "        df.loc[x - 1, 'file_name'] = f'song_{x}.mp3'\n",
    "        df.loc[x - 1, 'vocal'] = 'Avril Lavigne'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>vocal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>song_1.mp3</td>\n",
       "      <td>Look at the stars, look how they shine for you...</td>\n",
       "      <td>Chris Martin - Coldplay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>song_2.mp3</td>\n",
       "      <td>'Cause you're a sky, 'cause you're a sky full ...</td>\n",
       "      <td>Chris Martin - Coldplay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>song_3.mp3</td>\n",
       "      <td>I used to rule the world\\nSeas would rise when...</td>\n",
       "      <td>Chris Martin - Coldplay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>song_4.mp3</td>\n",
       "      <td>Ooh-ooh-ooh, ooh-ooh-ooh, ooh-ooh-ooh\\nOoh-ooh...</td>\n",
       "      <td>Chris Martin - Coldplay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>song_5.mp3</td>\n",
       "      <td>When you try your best, but you don't succeed\\...</td>\n",
       "      <td>Chris Martin - Coldplay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>song_6.mp3</td>\n",
       "      <td>Uh-huh, life's like this\\nUh-huh, uh-huh\\nThat...</td>\n",
       "      <td>Avril Lavigne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>song_7.mp3</td>\n",
       "      <td>I always needed time on my own\\nI never though...</td>\n",
       "      <td>Avril Lavigne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>song_8.mp3</td>\n",
       "      <td>I can be tough, I can be strong\\nBut with you,...</td>\n",
       "      <td>Avril Lavigne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>song_9.mp3</td>\n",
       "      <td>Hey, hey, you, you, I don't like your girlfrie...</td>\n",
       "      <td>Avril Lavigne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>song_10.mp3</td>\n",
       "      <td>You say that I'm messing with your head\\n(Yeah...</td>\n",
       "      <td>Avril Lavigne</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     file_name                                             lyrics  \\\n",
       "0   song_1.mp3  Look at the stars, look how they shine for you...   \n",
       "1   song_2.mp3  'Cause you're a sky, 'cause you're a sky full ...   \n",
       "2   song_3.mp3  I used to rule the world\\nSeas would rise when...   \n",
       "3   song_4.mp3  Ooh-ooh-ooh, ooh-ooh-ooh, ooh-ooh-ooh\\nOoh-ooh...   \n",
       "4   song_5.mp3  When you try your best, but you don't succeed\\...   \n",
       "5   song_6.mp3  Uh-huh, life's like this\\nUh-huh, uh-huh\\nThat...   \n",
       "6   song_7.mp3  I always needed time on my own\\nI never though...   \n",
       "7   song_8.mp3  I can be tough, I can be strong\\nBut with you,...   \n",
       "8   song_9.mp3  Hey, hey, you, you, I don't like your girlfrie...   \n",
       "9  song_10.mp3  You say that I'm messing with your head\\n(Yeah...   \n",
       "\n",
       "                     vocal  \n",
       "0  Chris Martin - Coldplay  \n",
       "1  Chris Martin - Coldplay  \n",
       "2  Chris Martin - Coldplay  \n",
       "3  Chris Martin - Coldplay  \n",
       "4  Chris Martin - Coldplay  \n",
       "5            Avril Lavigne  \n",
       "6            Avril Lavigne  \n",
       "7            Avril Lavigne  \n",
       "8            Avril Lavigne  \n",
       "9            Avril Lavigne  "
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = df['vocal'].apply(lambda x: 0 if x == 'Chris Martin - Coldplay' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>vocal</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>song_1.mp3</td>\n",
       "      <td>Look at the stars, look how they shine for you...</td>\n",
       "      <td>Chris Martin - Coldplay</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>song_2.mp3</td>\n",
       "      <td>'Cause you're a sky, 'cause you're a sky full ...</td>\n",
       "      <td>Chris Martin - Coldplay</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>song_3.mp3</td>\n",
       "      <td>I used to rule the world\\nSeas would rise when...</td>\n",
       "      <td>Chris Martin - Coldplay</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>song_4.mp3</td>\n",
       "      <td>Ooh-ooh-ooh, ooh-ooh-ooh, ooh-ooh-ooh\\nOoh-ooh...</td>\n",
       "      <td>Chris Martin - Coldplay</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>song_5.mp3</td>\n",
       "      <td>When you try your best, but you don't succeed\\...</td>\n",
       "      <td>Chris Martin - Coldplay</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>song_6.mp3</td>\n",
       "      <td>Uh-huh, life's like this\\nUh-huh, uh-huh\\nThat...</td>\n",
       "      <td>Avril Lavigne</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>song_7.mp3</td>\n",
       "      <td>I always needed time on my own\\nI never though...</td>\n",
       "      <td>Avril Lavigne</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>song_8.mp3</td>\n",
       "      <td>I can be tough, I can be strong\\nBut with you,...</td>\n",
       "      <td>Avril Lavigne</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>song_9.mp3</td>\n",
       "      <td>Hey, hey, you, you, I don't like your girlfrie...</td>\n",
       "      <td>Avril Lavigne</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>song_10.mp3</td>\n",
       "      <td>You say that I'm messing with your head\\n(Yeah...</td>\n",
       "      <td>Avril Lavigne</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     file_name                                             lyrics  \\\n",
       "0   song_1.mp3  Look at the stars, look how they shine for you...   \n",
       "1   song_2.mp3  'Cause you're a sky, 'cause you're a sky full ...   \n",
       "2   song_3.mp3  I used to rule the world\\nSeas would rise when...   \n",
       "3   song_4.mp3  Ooh-ooh-ooh, ooh-ooh-ooh, ooh-ooh-ooh\\nOoh-ooh...   \n",
       "4   song_5.mp3  When you try your best, but you don't succeed\\...   \n",
       "5   song_6.mp3  Uh-huh, life's like this\\nUh-huh, uh-huh\\nThat...   \n",
       "6   song_7.mp3  I always needed time on my own\\nI never though...   \n",
       "7   song_8.mp3  I can be tough, I can be strong\\nBut with you,...   \n",
       "8   song_9.mp3  Hey, hey, you, you, I don't like your girlfrie...   \n",
       "9  song_10.mp3  You say that I'm messing with your head\\n(Yeah...   \n",
       "\n",
       "                     vocal  label  \n",
       "0  Chris Martin - Coldplay      0  \n",
       "1  Chris Martin - Coldplay      0  \n",
       "2  Chris Martin - Coldplay      0  \n",
       "3  Chris Martin - Coldplay      0  \n",
       "4  Chris Martin - Coldplay      0  \n",
       "5            Avril Lavigne      1  \n",
       "6            Avril Lavigne      1  \n",
       "7            Avril Lavigne      1  \n",
       "8            Avril Lavigne      1  \n",
       "9            Avril Lavigne      1  "
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./dataset/songsdata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchaudio\n",
    "from torch.utils.data import Dataset \n",
    "import os\n",
    "\n",
    "\n",
    "class SongToLyricsDataset(Dataset):\n",
    "\n",
    "    def __init__(self, annotation_file, audio_dir, transformation, target_sr, num_samples):\n",
    "        self.annotations = pd.read_csv(annotation_file)\n",
    "        self.audio_dir = audio_dir\n",
    "        self.transformation = transformation\n",
    "        self.target_sr = target_sr\n",
    "        self.num_samples = num_samples\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "    \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        audio_sample_path = self._get_audio_sample_path(index)\n",
    "        label = self._get_audio_sample_label(index)\n",
    "        sig, sr = torchaudio.load(audio_sample_path)\n",
    "        sig = self._resample_sr(sig, sr)\n",
    "        sig = self._mix_down(sig)\n",
    "        sig = self._add_pad(sig)\n",
    "        sig = self.transformation(sig)\n",
    "        return sig, label\n",
    "    \n",
    "    def _add_pad(self, sig):\n",
    "        if sig.shape[1] < self.num_samples:\n",
    "            num_missing_sample = self.num_samples - sig.shape[1]\n",
    "            last_dim_padding = (0, num_missing_sample)\n",
    "            sig = nn.functional.pad(sig, last_dim_padding)\n",
    "        return sig\n",
    "\n",
    "    def _resample_sr(self, sig, sr):\n",
    "        if sr != self.target_sr:\n",
    "            resample = torchaudio.transforms.Resample(sr, self.target_sr)\n",
    "            sig = resample(sig)\n",
    "        return sig\n",
    "\n",
    "    def _mix_down(self, sig):\n",
    "        if sig.shape[0] != 1:\n",
    "            sig = torch.mean(sig, dim = 0, keepdim = True)\n",
    "\n",
    "        return sig\n",
    "\n",
    "    def _get_audio_sample_path(self, index):\n",
    "        return os.path.join(self.audio_dir, self.annotations.loc[index, 'file_name'])\n",
    "    \n",
    "    def _get_audio_sample_label(self, index):\n",
    "        return self.annotations.loc[index, 'label']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_RATE = 22050\n",
    "NUM_SAMPLES = 6615000 # 5 mins\n",
    "melS_spectrogram = torchaudio.transforms.MelSpectrogram(\n",
    "    sample_rate= SAMPLE_RATE,\n",
    "    n_fft=1024,\n",
    "    hop_length=512,\n",
    "    n_mels=64,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, stride = 1, padding = 2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride = 1, padding = 2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride = 1, padding = 2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride = 1, padding = 2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear = nn.Linear(517760, 2)\n",
    "        self.softmax = nn.Softmax(dim = 1)\n",
    "    \n",
    "    def forward(self, input_data):\n",
    "        x = self.conv1(input_data)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear(x)\n",
    "        predictions = self.softmax(logits)\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, data_loader, loss_fn, optimiser, device):\n",
    "    for inputs, targets in data_loader:\n",
    "        inputs= inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        predictions = model(inputs)\n",
    "        loss = loss_fn(predictions, targets)\n",
    "\n",
    "        optimiser.zero_grad()\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "\n",
    "    print(f'Loss = {loss.item()}')\n",
    "\n",
    "def train(model, data_loader, loss_fn, optimiser, device, epochs):\n",
    "    for i in range(epochs):\n",
    "        print(f\"----- Epoch {i + 1} -----\")\n",
    "        train_one_epoch(model, data_loader, loss_fn, optimiser, device)\n",
    "        print('------------------------------------')\n",
    "\n",
    "    print(\"Finish training\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "EPOCHS = 5\n",
    "LEARNING_RATE = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv2): Sequential(\n",
       "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv3): Sequential(\n",
       "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv4): Sequential(\n",
       "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear): Linear(in_features=517760, out_features=2, bias=True)\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn = CNN()\n",
    "cnn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimiser = torch.optim.Adam(cnn.parameters(), lr = LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def create_data_loader(train_data, batch_size):\n",
    "    train_dataloader = DataLoader(train_data, batch_size=batch_size)\n",
    "    return train_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WinError 2] The system cannot find the file specified: 'SongToLyrics'\n",
      "d:\\CUHK\\IERG4320\\Project\\SongToLyrics\n"
     ]
    }
   ],
   "source": [
    "%cd SongToLyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = './dataset'\n",
    "csv = '/songsdata.csv'\n",
    "STL = SongToLyricsDataset(folder + csv, folder, melS_spectrogram, SAMPLE_RATE, NUM_SAMPLES)\n",
    "train_data_loader = create_data_loader(STL, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Epoch 1 -----\n",
      "Loss = 1.31326162815094\n",
      "------------------------------------\n",
      "----- Epoch 2 -----\n",
      "Loss = 1.31326162815094\n",
      "------------------------------------\n",
      "----- Epoch 3 -----\n",
      "Loss = 1.31326162815094\n",
      "------------------------------------\n",
      "----- Epoch 4 -----\n",
      "Loss = 1.31326162815094\n",
      "------------------------------------\n",
      "----- Epoch 5 -----\n",
      "Loss = 1.31326162815094\n",
      "------------------------------------\n",
      "Finish training\n"
     ]
    }
   ],
   "source": [
    "train(cnn, train_data_loader, loss_fn, optimiser, device, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(cnn.state_dict(), 'vocalClassifier.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kazaf\\AppData\\Local\\Temp\\ipykernel_14280\\764746667.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(\"vocalClassifier.pt\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CNN()\n",
    "state_dict = torch.load(\"vocalClassifier.pt\")\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs = SongToLyricsDataset(folder + csv, folder, melS_spectrogram, SAMPLE_RATE, NUM_SAMPLES)\n",
    "data = create_data_loader(songs, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tensor([[[[3.2421e-20, 3.8307e-18, 1.7395e-11,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [3.0134e-19, 9.8860e-18, 2.2331e-11,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [2.2204e-19, 3.4007e-17, 1.9567e-11,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          ...,\n",
      "          [3.0472e-17, 1.4021e-13, 2.2473e-10,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [5.0080e-16, 6.1886e-13, 1.1961e-10,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [3.3226e-16, 3.6075e-13, 9.8837e-11,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]]]])\n",
      "1\n",
      "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]])\n",
      "2\n",
      "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]])\n",
      "3\n",
      "tensor([[[[3.2421e-20, 3.8307e-18, 1.7395e-11,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [3.0134e-19, 9.8860e-18, 2.2331e-11,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [2.2204e-19, 3.4007e-17, 1.9567e-11,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          ...,\n",
      "          [3.0472e-17, 1.4021e-13, 2.2473e-10,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [5.0080e-16, 6.1886e-13, 1.1961e-10,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [3.3226e-16, 3.6075e-13, 9.8837e-11,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]]]])\n",
      "4\n",
      "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]])\n",
      "5\n",
      "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]])\n",
      "6\n",
      "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]])\n",
      "7\n",
      "tensor([[[[3.4216e-29, 7.8390e-18, 2.1340e-12,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [3.7113e-28, 9.3770e-18, 4.3556e-12,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [5.2238e-28, 1.0852e-17, 1.8135e-12,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          ...,\n",
      "          [1.3406e-25, 1.1006e-14, 1.1462e-10,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [9.7762e-26, 1.3769e-14, 5.2073e-10,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [6.4204e-26, 6.4789e-15, 1.4573e-10,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]]]])\n",
      "8\n",
      "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]])\n",
      "9\n",
      "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]])\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for input, taret in data:\n",
    "    print(i)\n",
    "    print(input)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (128x4045 and 517760x2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[70], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m----> 3\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m# Tensor (1, 10) -> [ [0.1, 0.01, ..., 0.6] ]\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     predicted_index \u001b[38;5;241m=\u001b[39m predictions[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39margmax(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[32], line 39\u001b[0m, in \u001b[0;36mCNN.forward\u001b[1;34m(self, input_data)\u001b[0m\n\u001b[0;32m     37\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv4(x)\n\u001b[0;32m     38\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflatten(x)\n\u001b[1;32m---> 39\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear(x)\n\u001b[0;32m     40\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msoftmax(logits)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m predictions\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (128x4045 and 517760x2)"
     ]
    }
   ],
   "source": [
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model(input)\n",
    "    # Tensor (1, 10) -> [ [0.1, 0.01, ..., 0.6] ]\n",
    "    predicted_index = predictions[0].argmax(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'state_dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[59], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(model\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvocalClassifier.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'state_dict'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
